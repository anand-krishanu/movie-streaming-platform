{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121278ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install visualization libraries if missing\n",
    "%pip install matplotlib seaborn ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ae0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add current directory to path so we can import our modules\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from data.data_loader import DataLoader\n",
    "from models.recommender import RecommenderSystem\n",
    "\n",
    "# Initialize\n",
    "loader = DataLoader()\n",
    "recommender = RecommenderSystem(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3101560",
   "metadata": {},
   "source": [
    "### 1. View the Interaction Matrix (The 'Scoreboard')\n",
    "This shows how users have rated movies based on their behavior (Favorites=5, Watch Later=2, Views=1-3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw interaction data\n",
    "interactions_df = loader.get_interaction_matrix()\n",
    "\n",
    "print(f\"Total Interactions: {len(interactions_df)}\")\n",
    "print(f\"Unique Users: {interactions_df['user_id'].nunique()}\")\n",
    "print(f\"Unique Movies: {interactions_df['movie_id'].nunique()}\")\n",
    "\n",
    "# Show the first 10 rows\n",
    "display(interactions_df)\n",
    "\n",
    "# Visualize the distribution of scores\n",
    "if not interactions_df.empty:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(x='score', data=interactions_df)\n",
    "    plt.title('Distribution of Interaction Scores')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3d8903",
   "metadata": {},
   "source": [
    "### 2. View Movie Metadata\n",
    "This is the data used for Content-Based filtering (Genres, Ratings, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc1553",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = loader.get_movies_metadata()\n",
    "display(movies_df.shape)\n",
    "display(movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d967ac",
   "metadata": {},
   "source": [
    "### 3. Train the Model & Inspect Latent Features\n",
    "We will train the model and then look at the hidden 'User Features' matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f99000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "metrics = recommender.train()\n",
    "print(\"Training Metrics:\", metrics)\n",
    "\n",
    "# Inspect the User-Feature Matrix (Hidden Preferences)\n",
    "if recommender.user_features is not None:\n",
    "    user_features_df = pd.DataFrame(\n",
    "        recommender.user_features,\n",
    "        index=list(recommender.user_id_map.keys()),\n",
    "        columns=[f\"Feature_{i+1}\" for i in range(recommender.n_components)]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nUser Latent Features (Top 5 Users):\")\n",
    "    display(user_features_df.head())\n",
    "    \n",
    "    # Visualize the heatmap of features for first 10 users\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(user_features_df.head(10), cmap=\"viridis\")\n",
    "    plt.title(\"Hidden User Preferences (Latent Features)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a5ecd",
   "metadata": {},
   "source": [
    "### 4. Test Recommendations\n",
    "Pick a user ID from the interaction matrix above and see what the model recommends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31203d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a user ID from the interactions dataframe\n",
    "if not interactions_df.empty:\n",
    "    test_user_id = interactions_df.iloc[1]['user_id']\n",
    "    print(f\"Generating recommendations for User ID: {test_user_id}\")\n",
    "\n",
    "    recommendations = recommender.get_recommendations(test_user_id, n_recommendations=5)\n",
    "    \n",
    "    # Convert to DataFrame for nice display\n",
    "    recs_df = pd.DataFrame(recommendations)\n",
    "    \n",
    "    # Add movie titles\n",
    "    if not recs_df.empty:\n",
    "        # Helper to get title\n",
    "        def get_title(mid):\n",
    "            m = movies_df[movies_df['movie_id'] == mid]\n",
    "            return m.iloc[0]['title'] if not m.empty else \"Unknown\"\n",
    "        \n",
    "        recs_df['title'] = recs_df['movie_id'].apply(get_title)\n",
    "        display(recs_df[['title', 'score', 'reason', 'movie_id']])\n",
    "    else:\n",
    "        print(\"No recommendations found.\")\n",
    "else:\n",
    "    print(\"No data available to generate recommendations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037e6ce",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation Metrics\n",
    "We check the mathematical health of the model.\n",
    "* **Sparsity**: Percentage of empty cells in the user-movie matrix. If > 99.5%, the model struggles to find patterns.\n",
    "* **Reconstruction Error**: How well the model approximates the original ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9929bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1. Sparsity\n",
    "n_users = interactions_df['user_id'].nunique() if not interactions_df.empty else 0\n",
    "n_movies = interactions_df['movie_id'].nunique() if not interactions_df.empty else 0\n",
    "n_interactions = len(interactions_df)\n",
    "sparsity = 1 - (n_interactions / (n_users * n_movies)) if (n_users * n_movies) > 0 else 1.0\n",
    "\n",
    "# 2. Reconstruction Error\n",
    "reconstruction_err = 0.0\n",
    "if recommender.model is not None and hasattr(recommender.model, 'reconstruction_err_'):\n",
    "    reconstruction_err = recommender.model.reconstruction_err_\n",
    "\n",
    "print(f\"Matrix Sparsity: {sparsity:.2%}\")\n",
    "print(f\"Reconstruction Error: {reconstruction_err:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037fe23a",
   "metadata": {},
   "source": [
    "### 6. Content-Based Sanity Check\n",
    "Does the model understand which movies are similar? We pick a movie and ask for similar ones based on genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c80124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to find similar movies\n",
    "def check_content_similarity(movie_title, n=5):\n",
    "    try:\n",
    "        # Find movie ID\n",
    "        target_movie = movies_df[movies_df['title'] == movie_title]\n",
    "        if target_movie.empty:\n",
    "            return f\"Movie '{movie_title}' not found in database.\"\n",
    "            \n",
    "        movie_id = target_movie.iloc[0]['movie_id']\n",
    "        target_genres = target_movie.iloc[0]['genres']\n",
    "        \n",
    "        print(f\"Target: {movie_title} | Genres: {target_genres}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Get similar movies from recommender\n",
    "        similar_movies = recommender.get_similar_movies(movie_id, n_similar=n)\n",
    "        \n",
    "        results = []\n",
    "        for m in similar_movies:\n",
    "            # Get title for display\n",
    "            m_info = movies_df[movies_df['movie_id'] == m['movie_id']]\n",
    "            if not m_info.empty:\n",
    "                title = m_info.iloc[0]['title']\n",
    "                genres = m_info.iloc[0]['genres']\n",
    "                results.append({\"Title\": title, \"Genres\": genres, \"Score\": m['score']})\n",
    "            \n",
    "        return pd.DataFrame(results)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Pick the first movie in the DB to test\n",
    "if not movies_df.empty:\n",
    "    sample_movie = movies_df.iloc[0]['title']\n",
    "    display(check_content_similarity(sample_movie))\n",
    "else:\n",
    "    print(\"No movies to check.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ec945",
   "metadata": {},
   "source": [
    "### 7. Final Report Card\n",
    "Is the model good? We evaluate based on data volume and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf550233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Thresholds for \"Good\"\n",
    "THRESHOLDS = {\n",
    "    \"min_users\": 50,\n",
    "    \"min_movies\": 100,\n",
    "    \"min_interactions\": 500,\n",
    "    \"max_sparsity\": 0.995\n",
    "}\n",
    "\n",
    "# Gather Stats\n",
    "stats = {\n",
    "    \"Metric\": [\"Total Users\", \"Total Movies\", \"Total Interactions\", \"Sparsity\", \"Reconstruction Error\"],\n",
    "    \"Value\": [n_users, n_movies, n_interactions, f\"{sparsity:.2%}\", f\"{reconstruction_err:.4f}\"],\n",
    "    \"Status\": []\n",
    "}\n",
    "\n",
    "# Evaluate\n",
    "stats[\"Status\"].append(\"Good\" if n_users >= THRESHOLDS[\"min_users\"] else \"Low Data\")\n",
    "stats[\"Status\"].append(\"Good\" if n_movies >= THRESHOLDS[\"min_movies\"] else \"Low Data\")\n",
    "stats[\"Status\"].append(\"Good\" if n_interactions >= THRESHOLDS[\"min_interactions\"] else \"Low Data\")\n",
    "stats[\"Status\"].append(\"Good\" if sparsity < THRESHOLDS[\"max_sparsity\"] else \"Too Sparse\")\n",
    "stats[\"Status\"].append(\"N/A\") # Reconstruction error depends on scale\n",
    "\n",
    "# Create Report DataFrame\n",
    "report_df = pd.DataFrame(stats)\n",
    "\n",
    "print(\"=== MODEL HEALTH REPORT ===\")\n",
    "display(report_df)\n",
    "\n",
    "# Final Verdict\n",
    "print(\"\\n=== FINAL VERDICT ===\")\n",
    "if \"Low Data\" in stats[\"Status\"] or \"Too Sparse\" in stats[\"Status\"]:\n",
    "    print(\"⚠️  MODEL IS UNDER-TRAINED\")\n",
    "    print(\"Reason: Insufficient data. The model is currently relying heavily on content-based filtering (genres) and popularity.\")\n",
    "    print(\"Recommendation: Add more users and interactions to enable Collaborative Filtering.\")\n",
    "else:\n",
    "    print(\"✅ MODEL IS HEALTHY\")\n",
    "    print(\"The system has enough data to find meaningful user patterns.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
